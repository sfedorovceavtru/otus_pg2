# Домашнее задание 9

1. Создал кластер k8s из консоли яндекса
2. Подклбчился к своей ВМ и инициализировал yc (https://cloud.yandex.ru/docs/cli/operations/install-cli)
```
curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash
yc init
yc managed-kubernetes cluster get-credentials otus-k8s-cluster --external
```
```
Context 'yc-otus-k8s-cluster' was added as default to kubeconfig '/home/otus/.kube/config'.
Check connection to cluster using 'kubectl cluster-info --kubeconfig /home/otus/.kube/config'.

Note, that authentication depends on 'yc' and its config profile 'default'.
To access clusters using the Kubernetes API, please use Kubernetes Service Account.
```
3. После установки проверяю список кластеров
```
yc container cluster list
+----------------------+------------------+---------------------+---------+---------+------------------------+---------------------+
|          ID          |       NAME       |     CREATED AT      | HEALTH  | STATUS  |   EXTERNAL ENDPOINT    |  INTERNAL ENDPOINT  |
+----------------------+------------------+---------------------+---------+---------+------------------------+---------------------+
| catn3vn5rmi4up1ipj5r | otus-k8s-cluster | 2023-06-21 09:27:56 | HEALTHY | RUNNING | https://158.160.41.226 | https://10.128.0.24 |
+----------------------+------------------+---------------------+---------+---------+------------------------+---------------------+
```
Проверяем список нодов
```
yc container cluster list-node-groups catn3vn5rmi4up1ipj5r
+----+------+-------------------+------------+--------+------+
| ID | NAME | INSTANCE GROUP ID | CREATED AT | STATUS | SIZE |
+----+------+-------------------+------------+--------+------+
```
Нодов пока нет
Проверяю диски
```
yc compute disk list
+----------------------+------+-------------+---------------+--------+----------------------+-------------+
|          ID          | NAME |    SIZE     |     ZONE      | STATUS |     INSTANCE IDS     | DESCRIPTION |
+----------------------+------+-------------+---------------+--------+----------------------+-------------+
| fhmr446khsqpmthmlbie |      | 19327352832 | ru-central1-a | READY  | fhmmrds6qkgmk7nmo9oj |             |
+----------------------+------+-------------+---------------+--------+----------------------+-------------+
```
4. Создаю из консоли в кластере otus-k8s-cluster три ноды и проверяю
```
yc container cluster list-node-groups catn3vn5rmi4up1ipj5r

+----------------------+----------------+----------------------+---------------------+---------+------+
|          ID          |      NAME      |  INSTANCE GROUP ID   |     CREATED AT      | STATUS  | SIZE |
+----------------------+----------------+----------------------+---------------------+---------+------+
| cat14simnh0c5i1hob6i | postgres-nodes | cl103lnor9l02caonrc6 | 2023-06-21 10:09:36 | RUNNING |    3 |
+----------------------+----------------+----------------------+---------------------+---------+------+
```
```
kubectl get all
NAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.128.1   <none>        443/TCP   38m
```
```
kubectl get nodes
NAME                        STATUS   ROLES    AGE     VERSION
cl103lnor9l02caonrc6-azyr   Ready    <none>   4m57s   v1.23.14
cl103lnor9l02caonrc6-utox   Ready    <none>   5m8s    v1.23.14
cl103lnor9l02caonrc6-ywox   Ready    <none>   4m49s   v1.23.14
```
вижу три созданные ноды

5. Устанавливаю хелм
```
curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
```
Устанавливаю postgresql-ha
```
otus@otus:~$ helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories
otus@otus:~$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "bitnami" chart repository
Update Complete. ⎈Happy Helming!⎈
otus@otus:~$ helm install my-release bitnami/postgresql-ha
NAME: my-release
LAST DEPLOYED: Wed Jun 21 11:16:29 2023
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: postgresql-ha
CHART VERSION: 11.7.6
APP VERSION: 15.3.0
** Please be patient while the chart is being deployed **
PostgreSQL can be accessed through Pgpool via port 5432 on the following DNS name from within your cluster:

    my-release-postgresql-ha-pgpool.default.svc.cluster.local

Pgpool acts as a load balancer for PostgreSQL and forward read/write connections to the primary node while read-only connections are forwarded to standby nodes.

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.password}" | base64 -d)

To get the password for "repmgr" run:

    export REPMGR_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.repmgr-password}" | base64 -d)

To connect to your database run the following command:

    kubectl run my-release-postgresql-ha-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql-repmgr:15.3.0-debian-11-r6 --env="PGPASSWORD=$POSTGRES_PASSWORD"  \
        --command -- psql -h my-release-postgresql-ha-pgpool -p 5432 -U postgres -d postgres

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/my-release-postgresql-ha-pgpool 5432:5432 &
    psql -h 127.0.0.1 -p 5432 -U postgres -d postgres
```
Получаю пароли
```
export POSTGRES_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.password}" | base64 -d)
export REPMGR_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.repmgr-password}" | base64 -d)
export ADMIN_PASSWORD=$(kubectl get secret --namespace "default" my-release-postgresql-ha-pgpool -o jsonpath="{.data.admin-password}" | base64 --decode)
echo $ADMIN_PASSWORD
echo $POSTGRES_PASSWORD 
echo $REPMGR_PASSWORD 
```

6. Смотрю все ресурсы в kubectl
```
otus@otus:~$ kubectl get all
NAME                                                   READY   STATUS    RESTARTS      AGE
pod/my-release-postgresql-ha-pgpool-7cf965994f-w8jcd   1/1     Running   0             16m
pod/my-release-postgresql-ha-postgresql-0              1/1     Running   0             16m
pod/my-release-postgresql-ha-postgresql-1              1/1     Running   1 (15m ago)   16m
pod/my-release-postgresql-ha-postgresql-2              1/1     Running   0             16m
```
Вижу три ноды, одна нода уже растартанулась
```
NAME                                                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/kubernetes                                     ClusterIP   10.96.128.1     <none>        443/TCP    117m
service/my-release-postgresql-ha-pgpool                ClusterIP   10.96.169.229   <none>        5432/TCP   16m
service/my-release-postgresql-ha-postgresql            ClusterIP   10.96.211.114   <none>        5432/TCP   16m
service/my-release-postgresql-ha-postgresql-headless   ClusterIP   None            <none>        5432/TCP   16m
```
Вижу информацию по сервисам
```
NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/my-release-postgresql-ha-pgpool   1/1     1            1           16m

NAME                                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/my-release-postgresql-ha-pgpool-7cf965994f   1         1         1       16m

NAME                                                   READY   AGE
statefulset.apps/my-release-postgresql-ha-postgresql   3/3     16m
```
7. Подключаюсь к кластеру
```
otus@otus:~$ kubectl run my-release-postgresql-ha-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql-repmgr:15.3.0-debian-11-r6 --env="PGPASSWORD=$POSTGRES_PASSWORD"  \
        --command -- psql -h my-release-postgresql-ha-pgpool -p 5432 -U postgres -d postgres
If you don't see a command prompt, try pressing enter.

postgres=# \l
                                                 List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    | ICU Locale | Locale Provider |   Access privileges
-----------+----------+----------+-------------+-------------+------------+-----------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
(4 rows)

postgres=#
```
Вижу доп.базу repmgr    

8. Делаю перенаправление соединение с локальных портов через port-forward и подключаюсь к кластеру из psql
```
$ sudo apt install postgresql-client
$ kubectl port-forward --namespace default svc/my-release-postgresql-ha-pgpool 5432:5432 & psql -h 127.0.0.1 -p 5432 -U postgres -d postgres
Forwarding from 127.0.0.1:5432 -> 5432
Forwarding from [::1]:5432 -> 5432
Handling connection for 5432
Password for user postgres:
Handling connection for 5432
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1), server 15.3)
WARNING: psql major version 14, server major version 15.
         Some psql features might not work.
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

postgres=#
```
9. Создал БД otus
```
postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(5 rows)
```
10. Удалил мастер поду
```
$ kubectl delete pod/my-release-postgresql-ha-postgresql-0
pod "my-release-postgresql-ha-postgresql-0" deleted
```
Проверяю что получилось
```
postgres=# \l
server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
The connection to the server was lost. Attempting reset: Succeeded.
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1), server 15.3)
WARNING: psql major version 14, server major version 15.
         Some psql features might not work.
postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(5 rows)
```
11. Удалил другую поду
```
otus@otus:~$ kubectl delete pod/my-release-postgresql-ha-postgresql-1
pod "my-release-postgresql-ha-postgresql-1" deleted
```
Смотрю в постгре:
```
postgres=# \l
FATAL:  unable to read data from DB node 1
DETAIL:  EOF encountered with backend
server closed the connection unexpectedly
        This probably means the server terminated abnormally
        before or while processing the request.
The connection to the server was lost. Attempting reset: Failed.
```
В перенаплавлении соединения слетело соединение
```
E0621 12:36:22.528270    6131 portforward.go:409] an error occurred forwarding 5432 -> 5432: error forwarding port 5432 to pod fe5f9e30591f6eda4d0a9b6049780b401deaf66b367006f11f9a6d9e0de730c7, uid : failed to execute portforward in network namespace "/var/run/netns/cni-1f28858d-ff3b-5e72-626a-e04b6098f336": read tcp4 127.0.0.1:43072->127.0.0.1:5432: read: connection reset by peer
error: lost connection to pod
```
12. Делаю новое соединение
```
otus@otus:~$ kubectl port-forward --namespace default svc/my-release-postgresql-ha-pgpool 5432:5432
Forwarding from 127.0.0.1:5432 -> 5432
Forwarding from [::1]:5432 -> 5432
Handling connection for 5432
Handling connection for 5432
```
Проверяю соединение
```
otus@otus:~$ psql -h 127.0.0.1 -p 5432 -U postgres -d postgres
Password for user postgres:
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1), server 15.3)
WARNING: psql major version 14, server major version 15.
         Some psql features might not work.
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(5 rows)

postgres=#
```
Останавливаю перенаправление
```
^Z
[1]+  Stopped                 kubectl port-forward --namespace default svc/my-release-postgresql-ha-pgpool 5432:5432
```
13. Захожу на pod pg_pool
```
kubectl exec -it pod/my-release-postgresql-ha-pgpool-7cf965994f-w8jcd -- bash
I have no name!@my-release-postgresql-ha-pgpool-7cf965994f-w8jcd:/$
```
Подключаюсь к кластеру
```
psql -U postgres -p 5432 -h localhost
Password for user postgres:
psql (14.8, server 15.3)
WARNING: psql major version 14, server major version 15.
         Some psql features might not work.
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(5 rows)

postgres=#
```
14. Смотрю что в repmgr
```
otus@otus:~$ kubectl exec -it pod/my-release-postgresql-ha-postgresql-1 -- /opt/bitnami/scripts/postgresql-repmgr/entrypoint.sh repmgr -f /opt/bitnami/repmgr/conf/repmgr.conf cluster show
postgresql-repmgr 12:55:00.79
postgresql-repmgr 12:55:00.79 Welcome to the Bitnami postgresql-repmgr container
postgresql-repmgr 12:55:00.79 Subscribe to project updates by watching https://github.com/bitnami/containers
postgresql-repmgr 12:55:00.79 Submit issues and feature requests at https://github.com/bitnami/containers/issues
postgresql-repmgr 12:55:00.80

 ID   | Name                                  | Role    | Status    | Upstream                              | Location | Priority | Timeline | Connection string                                              
------+---------------------------------------+---------+-----------+---------------------------------------+----------+----------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 1000 | my-release-postgresql-ha-postgresql-0 | standby |   running | my-release-postgresql-ha-postgresql-1 | default  | 100      | 4        | user=repmgr password=XtSghyaylB host=my-release-postgresql-ha-postgresql-0.my-release-postgresql-ha-postgresql-headless.default.svc.cluster.local dbname=repmgr port=5432 connect_timeout=5
 1001 | my-release-postgresql-ha-postgresql-1 | primary | * running |                                       | default  | 100      | 4        | user=repmgr password=XtSghyaylB host=my-release-postgresql-ha-postgresql-1.my-release-postgresql-ha-postgresql-headless.default.svc.cluster.local dbname=repmgr port=5432 connect_timeout=5
 1002 | my-release-postgresql-ha-postgresql-2 | standby |   running | my-release-postgresql-ha-postgresql-1 | default  | 100      | 4        | user=repmgr password=XtSghyaylB host=my-release-postgresql-ha-postgresql-2.my-release-postgresql-ha-postgresql-headless.default.svc.cluster.local dbname=repmgr port=5432 connect_timeout=5
```
Вижу, что pod1 - мастер

15. Добавляю внешнего лоад балансера
```
$ helm upgrade my-release bitnami/postgresql-ha --set service.type=LoadBalancer --set postgresql.password=$POSTGRES_PASSWORD --set postgresql.repmgrPassword=$REPMGR_PASSWORD --set pgpool.adminPassword=$ADMIN_PASSWORD
Release "my-release" has been upgraded. Happy Helming!
NAME: my-release
LAST DEPLOYED: Wed Jun 21 12:59:17 2023
NAMESPACE: default
STATUS: deployed
REVISION: 2
TEST SUITE: None
NOTES:
CHART NAME: postgresql-ha
CHART VERSION: 11.7.6
APP VERSION: 15.3.0
** Please be patient while the chart is being deployed **
PostgreSQL can be accessed through Pgpool via port 5432 on the following DNS name from within your cluster:

    my-release-postgresql-ha-pgpool.default.svc.cluster.local

Pgpool acts as a load balancer for PostgreSQL and forward read/write connections to the primary node while read-only connections are forwarded to standby nodes.

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.password}" | base64 -d)

To get the password for "repmgr" run:

    export REPMGR_PASSWORD=$(kubectl get secret --namespace default my-release-postgresql-ha-postgresql -o jsonpath="{.data.repmgr-password}" | base64 -d)

To connect to your database run the following command:

    kubectl run my-release-postgresql-ha-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql-repmgr:15.3.0-debian-11-r6 --env="PGPASSWORD=$POSTGRES_PASSWORD"  \
        --command -- psql -h my-release-postgresql-ha-pgpool -p 5432 -U postgres -d postgres

To connect to your database from outside the cluster execute the following commands:

  NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        Watch the status with: 'kubectl get svc --namespace default -w my-release-postgresql-ha-pgpool

    export SERVICE_IP=$(kubectl get svc --namespace default my-release-postgresql-ha-pgpool --template "{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}")
    PGPASSWORD="$POSTGRES_PASSWORD" psql -h $SERVICE_IP -p 5432  -U postgres -d postgres
otus@otus:~$ kubectl get all
NAME                                                   READY   STATUS    RESTARTS   AGE
pod/my-release-postgresql-ha-pgpool-7cf965994f-w8jcd   1/1     Running   0          102m
pod/my-release-postgresql-ha-postgresql-0              1/1     Running   0          9m5s
pod/my-release-postgresql-ha-postgresql-1              1/1     Running   0          22m
pod/my-release-postgresql-ha-postgresql-2              1/1     Running   0          102m

NAME                                                   TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
service/kubernetes                                     ClusterIP      10.96.128.1     <none>          443/TCP          3h24m
service/my-release-postgresql-ha-pgpool                LoadBalancer   10.96.169.229   51.250.89.215   5432:31774/TCP   102m
service/my-release-postgresql-ha-postgresql            ClusterIP      10.96.211.114   <none>          5432/TCP         102m
service/my-release-postgresql-ha-postgresql-headless   ClusterIP      None            <none>          5432/TCP         102m

NAME                                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/my-release-postgresql-ha-pgpool   1/1     1            1           102m

NAME                                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/my-release-postgresql-ha-pgpool-7cf965994f   1         1         1       102m

NAME                                                   READY   AGE
statefulset.apps/my-release-postgresql-ha-postgresql   3/3     102m
```
Вижу внешний IP у pgpool
```
otus@otus:~$ export SERVICE_IP=$(kubectl get svc --namespace default my-release-postgresql-ha-pgpool --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
otus@otus:~$ echo $SERVICE_IP
51.250.89.215
```
Проверяю подключение
```
otus@otus:~$ PGPASSWORD=$POSTGRES_PASSWORD psql -h $SERVICE_IP -p 5432 -U postgres -d postgres
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1), server 15.3)
WARNING: psql major version 14, server major version 15.
         Some psql features might not work.
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 repmgr    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(5 rows)

postgres=#
```

**pg_auto_failover**

1. Устанавил pg_auto_failover
```
sudo apt-get install pg-auto-failover-cli
sudo apt-get install postgresql-14-auto-failover
```
2. Установил и запустил монитор
```
otus@otus1:~$ sudo -u postgres pg_autoctl create monitor --auth trust --ssl-self-signed --pgctl /usr/lib/postgresql/14/bin/pg_ctl --pgdata /var/lib/postgresql/14/main/monitor/ --pgport 5000
14:47:11 4536 INFO  Using default --ssl-mode "require"
14:47:11 4536 INFO  Using --ssl-self-signed: pg_autoctl will create self-signed certificates, allowing for encrypted network traffic
14:47:11 4536 WARN  Self-signed certificates provide protection against eavesdropping; this setup does NOT protect against Man-In-The-Middle attacks nor Impersonation attacks.
14:47:11 4536 WARN  See https://www.postgresql.org/docs/current/libpq-ssl.html for details
14:47:11 4536 WARN  Failed to get a local IP address for hostname "otus1"
14:47:11 4536 INFO  Connecting to 8.8.8.8 (port 53)
14:47:11 4536 INFO  Using local IP address "10.128.0.32" as the --hostname.
14:47:11 4536 INFO  Initialising a PostgreSQL cluster at "/var/lib/postgresql/14/main/monitor/"
14:47:11 4536 INFO  /usr/lib/postgresql/14/bin/pg_ctl initdb -s -D /var/lib/postgresql/14/main/monitor/ --option '--auth=trust'
14:47:12 4536 WARN  could not change directory to "/home/otus": Permission denied
14:47:12 4536 INFO   /usr/bin/openssl req -new -x509 -days 365 -nodes -text -out /var/lib/postgresql/14/main/monitor/server.crt -keyout /var/lib/postgresql/14/main/monitor/server.key -subj "/CN=10.128.0.32"
14:47:12 4536 INFO  Started pg_autoctl postgres service with pid 4556
14:47:12 4556 INFO   /usr/bin/pg_autoctl do service postgres --pgdata /var/lib/postgresql/14/main/monitor/ -v
14:47:12 4536 INFO  Started pg_autoctl monitor-init service with pid 4557
14:47:12 4562 INFO   /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main/monitor -p 5000 -h *
14:47:12 4556 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/14/main/monitor" on port 5000 with pid 4562
14:47:13 4557 WARN  NOTICE:  installing required extension "btree_gist"
14:47:13 4557 INFO  Granting connection privileges on 10.128.0.0/24
14:47:13 4557 INFO  Reloading Postgres configuration and HBA rules
14:47:13 4557 INFO  Your pg_auto_failover monitor instance is now ready on port 5000.
14:47:13 4557 INFO  Monitor has been successfully initialized.
14:47:13 4536 WARN  pg_autoctl service monitor-init exited with exit status 0
14:47:13 4556 INFO  Postgres controller service received signal SIGTERM, terminating
14:47:13 4556 INFO  Stopping pg_autoctl postgres service
14:47:13 4556 INFO  /usr/lib/postgresql/14/bin/pg_ctl --pgdata /var/lib/postgresql/14/main/monitor --wait stop --mode fast
14:47:13 4536 INFO  Waiting for subprocesses to terminate.
14:47:13 4536 INFO  Stop pg_autoctl
```
3. Команда pg_autoctl show systemd выводит файл systemd unit, который вы можете использовать для настройки зарегистрированной во время загрузки службы для pg_auto_failover на вашем компьютере.
```
sudo su postgres
export PGDATA=/var/lib/postgresql/14/main/monitor/
pg_autoctl show systemd

14:54:11 4617 INFO  HINT: to complete a systemd integration, run the following commands (as root):
14:54:11 4617 INFO  pg_autoctl -q show systemd --pgdata "/var/lib/postgresql/14/main/monitor" | tee /etc/systemd/system/pgautofailover.service
14:54:11 4617 INFO  systemctl daemon-reload
14:54:11 4617 INFO  systemctl enable pgautofailover
14:54:11 4617 INFO  systemctl start pgautofailover
[Unit]
Description = pg_auto_failover

[Service]
WorkingDirectory = /var/lib/postgresql
Environment = 'PGDATA=/var/lib/postgresql/14/main/monitor'
User = postgres
ExecStart = /usr/bin/pg_autoctl run
Restart = always
StartLimitBurst = 0
ExecReload = /usr/bin/pg_autoctl reload

[Install]
WantedBy = multi-user.target
```
4. Выполнил команды из выведенного файла, установил службу. Проверяю ее статус
```
systemctl status pgautofailover

● pgautofailover.service - pg_auto_failover
     Loaded: loaded (/etc/systemd/system/pgautofailover.service; enabled; vendor preset: enabled)
     Active: active (running) since Wed 2023-06-21 15:19:09 UTC; 9s ago
   Main PID: 3894 (pg_autoctl)
      Tasks: 15 (limit: 2218)
     Memory: 32.4M
        CPU: 98ms
     CGroup: /system.slice/pgautofailover.service
             ├─3894 /usr/bin/pg_autoctl run
             ├─3897 "pg_autoctl: start/stop postgres" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ">
             ├─3898 "pg_autoctl: monitor listener" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ">
             ├─3907 /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main/monitor -p 5000 -h "*"
             ├─3908 "postgres: pg_auto_failover monitor: logger " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3910 "postgres: pg_auto_failover monitor: checkpointer " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3911 "postgres: pg_auto_failover monitor: background writer " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3912 "postgres: pg_auto_failover monitor: walwriter " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3913 "postgres: pg_auto_failover monitor: autovacuum launcher " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3914 "postgres: pg_auto_failover monitor: stats collector " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3915 "postgres: pg_auto_failover monitor: pg_auto_failover monitor " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3916 "postgres: pg_auto_failover monitor: logical replication launcher " "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
             ├─3917 "postgres: pg_auto_failover monitor: pg_auto_failover monitor healthcheck worker postgres "
             ├─3918 "postgres: pg_auto_failover monitor: pg_auto_failover monitor healthcheck worker pg_auto_failover "
             └─3920 "postgres: pg_auto_failover monitor: autoctl_node pg_auto_failover [local] idle" "" "" "" "" "" "" "" "" ""

Jun 21 15:19:09 otus pg_autoctl[3894]: 15:19:09 3894 INFO  Started pg_autoctl postgres service with pid 3897
Jun 21 15:19:09 otus pg_autoctl[3897]: 15:19:09 3897 INFO   /usr/bin/pg_autoctl do service postgres --pgdata /var/lib/postgresql/14/main/monitor -v
Jun 21 15:19:09 otus pg_autoctl[3894]: 15:19:09 3894 INFO  Started pg_autoctl listener service with pid 3898
Jun 21 15:19:09 otus pg_autoctl[3898]: 15:19:09 3898 INFO   /usr/bin/pg_autoctl do service listener --pgdata /var/lib/postgresql/14/main/monitor -v
Jun 21 15:19:09 otus pg_autoctl[3898]: 15:19:09 3898 INFO  Managing the monitor at postgres://autoctl_node@10.128.0.14:5000/pg_auto_failover?sslmode=require
Jun 21 15:19:09 otus pg_autoctl[3898]: 15:19:09 3898 INFO  Reloaded the new configuration from "/var/lib/postgresql/.config/pg_autoctl/var/lib/postgresql/14/main/monitor/pg_autoctl.cfg"
Jun 21 15:19:10 otus pg_autoctl[3907]: 15:19:10 3907 INFO   /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main/monitor -p 5000 -h *
Jun 21 15:19:10 otus pg_autoctl[3897]: 15:19:10 3897 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/14/main/monitor" on port 5000 with pid 3907
Jun 21 15:19:10 otus pg_autoctl[3898]: 15:19:10 3898 INFO  The version of extension "pgautofailover" is "1.6" on the monitor
Jun 21 15:19:10 otus pg_autoctl[3898]: 15:19:10 3898 INFO  Contacting the monitor to LISTEN to its events.

```
5. Получил URI Postgres (строку подключения) для узла монитора
```
$ sudo su postgres
postgres@otus:/home/otus$ export PGDATA=/var/lib/postgresql/14/main/monitor/
postgres@otus:/home/otus$ pg_autoctl show uri

        Type |    Name | Connection String
-------------+---------+-------------------------------
     monitor | monitor | postgres://autoctl_node@10.128.0.13:5000/pg_auto_failover?sslmode=require
   formation | default |
```
6. Установил мастер-ноду
```
pg_autoctl show uri 
otus@otus1:~$ sudo -u postgres pg_autoctl create postgres --auth trust --ssl-self-signed --pgdata /var/lib/postgresql/14/main/postgres_01/ --hostname localhost --pgport 5001 --monitor 'postgres://autoctl_node@localhost:5000/pg_auto_failover?sslmode=require'
```
и запустил ее
```
export PGDATA=/var/lib/postgresql/14/main/postgres_01/
pg_autoctl run
16:07:37 27187 INFO  Started pg_autoctl postgres service with pid 27190
16:07:37 27190 INFO   /usr/bin/pg_autoctl do service postgres --pgdata /var/lib/postgresql/14/main/postgres_01/ -v
16:07:37 27187 INFO  Started pg_autoctl node-active service with pid 27191
16:07:37 27191 INFO   /usr/bin/pg_autoctl do service node-active --pgdata /var/lib/postgresql/14/main/postgres_01/ -v
16:07:37 27191 INFO  Reloaded the new configuration from "/var/lib/postgresql/.config/pg_autoctl/var/lib/postgresql/14/main/postgres_01/pg_autoctl.cfg"
16:07:37 27191 INFO  pg_autoctl service is running, current state is "wait_primary"
16:07:37 27191 WARN  Failed to update the keeper's state from the local PostgreSQL instance.
16:07:37 27191 INFO  Fetched current list of 1 other nodes from the monitor to update HBA rules, including 1 changes.
16:07:37 27191 INFO  Ensuring HBA rules for node 2 "node_2" (localhost:5002)
16:07:37 27206 INFO   /usr/lib/postgresql/14/bin/postgres -D /var/lib/postgresql/14/main/postgres_01 -p 5001 -h *
16:07:37 27191 WARN  PostgreSQL was not running, restarted with pid 27206
16:07:37 27190 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/14/main/postgres_01" on port 5001 with pid 27206
16:07:38 27191 INFO  Updated the keeper's state from the local PostgreSQL instance, which is running
16:07:38 27191 INFO  pg_autoctl managed to ensure current state "wait_primary": PostgreSQL is running
16:07:38 27191 INFO  New state for this node (node 1, "node_1") (localhost:5001): wait_primary ➜ wait_primary
```
7. В другом окне сделал вторую ноду
```
otus@otus1:~$ sudo -u postgres pg_autoctl create postgres --auth trust --ssl-self-signed --pgdata /var/lib/postgresql/14/main/postgres_02/ --hostname localhost --pgport 5002 --monitor 'postgres://autoctl_node@localhost:5000/pg_auto_failover?sslmode=require'
```
и тоже запустил ее
```
export PGDATA=/var/lib/postgresql/14/main/postgres_02/
pg_autoctl run
```
8. В третьем терминале смотрю:
```
postgres@otus-01:/home/otus$ pg_autoctl show uri
        Type |    Name | Connection String
-------------+---------+-------------------------------
     monitor | monitor | postgres://autoctl_node@10.128.0.13:5000/pg_auto_failover?sslmode=require
   formation | default | postgres://localhost:5002,localhost:5001/postgres?target_session_attrs=read-write&sslmode=require

postgres@otus-01:/home/otus$ pg_autoctl show state
  Name |  Node |      Host:Port |       TLI: LSN |   Connection |      Reported State |      Assigned State
-------+-------+----------------+----------------+--------------+---------------------+--------------------
node_1 |     1 | localhost:5001 |   1: 0/3000148 |   read-write |             primary |             primary
node_2 |     2 | localhost:5002 |   1: 0/3000148 |    read-only |           secondary |           secondary
```
9. Захожу в потсгрес на мастер ноде и создаю БД
```
postgres@otus-01:/home/otus$ psql -p 5001
could not change directory to "/home/otus": Permission denied
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1))
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(3 rows)

postgres=# create database otus;
CREATE DATABASE
postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

postgres=#
```
Захожу на второй ноде и вижу, что данные на месте
```
postgres@otus-01:/home/otus$ psql -p 5002
could not change directory to "/home/otus": Permission denied
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1))
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

postgres=#
```
Затем я закрыл ноду 1
```
postgres@otus-01:/home/otus$ pg_autoctl show state
  Name |  Node |      Host:Port |       TLI: LSN |   Connection |      Reported State |      Assigned State
-------+-------+----------------+----------------+--------------+---------------------+--------------------
node_1 |     1 | localhost:5001 |   1: 0/3000ED8 | read-write ! |             primary |             demoted
node_2 |     2 | localhost:5002 |   2: 0/30020D0 |   read-write |        wait_primary |        wait_primary

postgres@otus-01:/home/otus$ psql -p 5001
could not change directory to "/home/otus": Permission denied
psql: error: connection to server on socket "/var/run/postgresql/.s.PGSQL.5002" failed: No such file or directory
        Is the server running locally and accepting connections on that socket?
Со второй ноды создал БД
postgres@otus-01:/home/otus$ psql -p 5002
could not change directory to "/home/otus": Permission denied
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1))
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
(4 rows)

postgres=# create database utus1;
CREATE DATABASE
```
Заново запустил первую ноду и проверил
```
postgres@otus-01:/home/otus$ psql -p 5001
could not change directory to "/home/otus": Permission denied
psql (14.8 (Ubuntu 14.8-0ubuntu0.22.04.1))
Type "help" for help.

postgres=# \l
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges
-----------+----------+----------+-------------+-------------+-----------------------
 otus      | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +
           |          |          |             |             | postgres=CTc/postgres
 utus1     | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |
(5 rows)

```

**Третья задача** (в процессе)


1. Отключаем SELINUX:
```
sudo nano /etc/selinux/config
SELINUX=disabled
```
2. Настраиваем имя хоста и шлюзы узлов:
```
sudo nano /etc/sysconfig/network
```
node1:
```
NETWORKING=yes
NETWORKING_IPV6=no
HOSTNAME=cent1.ru-central1.internal
GATEWAY=10.128.0.21
```
node2:
```
NETWORKING=yes
NETWORKING_IPV6=no
HOSTNAME=cent2.ru-central1.internal
GATEWAY=10.128.0.14
```
3. Настраиваем сетевые интерфейсы:
```
sudo nano /etc/sysconfig/network-scripts/ifcfg-eth0
```
node1:
```
BOOTPROTO=static
IPADDR=10.128.0.21
NETMASK=255.255.255.0
DEVICE=eth0
HWADDR=d0:0d:12:f7:df:52
ONBOOT=yes
STARTMODE=auto
TYPE=Ethernet
USERCTL=no
```
node2:
```
BOOTPROTO=static
IPADDR=10.128.0.14
NETMASK=255.255.255.0
DEVICE=eth0
HWADDR=d0:0d:38:ec:cf:8d
ONBOOT=yes
STARTMODE=auto
TYPE=Ethernet
USERCTL=no


